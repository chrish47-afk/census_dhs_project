{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137044cb-6ca3-4c35-b8a9-7775ecc1f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pwd\n",
    "cd Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d380a9-9059-4798-9798-c62c1367dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from census import Census\n",
    "from us import states\n",
    "import pandas as pd\n",
    "\n",
    "## Simple Call ##\n",
    "'''Example US Census API Call\n",
    "* The following pulls in Total Population('B05001_001E') for California for 2022(years can be specified) into a Dataframe.\n",
    "* This should run relatively quick and efficient. Approx 2minutes or less.\n",
    "'''\n",
    "# Your Census API key\n",
    "API_KEY = \"Enter Key\" #Change as necessary\n",
    "\n",
    "# Initialize the Census API\n",
    "c = Census(API_KEY)\n",
    "\n",
    "# Query ACS 5-Year Data for 2022\n",
    "data = c.acs5.state(\n",
    "    ('B05001_001E'),  #Total population\n",
    "    '06')\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_file = \"acs5_ca_data.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Explore the data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0374bdb-8425-4602-bc88-755b2ea08278",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dependencies\n",
    "import pandas as pd\n",
    "from census import Census\n",
    "from us import states\n",
    "\n",
    "## A more detailed Call ##\n",
    "'''Example US Census by county API Call\n",
    "* The following pulls in Total Population('B05001_001E') for Washington counties for 2015,2022(years can be specified) into a Dataframe.\n",
    "* This pulls in all county level data for Washington for the specified years. For variables NAME and 'B05001_001E'. NAME is simply the full county name plus subdivision name.\n",
    "* \n",
    "'''\n",
    "# Your Census API key\n",
    "key = \"Enter Key\" #Change this as necessary.\n",
    "c = Census(key)\n",
    "# Choose relevant census dataset\n",
    "dataset = c.acs5\n",
    "# Assign variable codes and their corresponding labels\n",
    "variables = ('NAME', 'B05001_001E')\n",
    "labels =    ('NAME', 'Place of Birth for the Foreign-Born Population in the United States')\n",
    "# Choose desired geographic aggregation level\n",
    "geo = 'county subdivision:*'\n",
    "\n",
    "# Year\n",
    "year = 2015 #2015, 2022\n",
    "\n",
    "# Choose filter criteria (geographic extent)\n",
    "county_code = '033'\n",
    "criteria = f'state:{states.WA.fips} county:{county_code}'\n",
    "# Run query and store as DataFrame\n",
    "r = dataset.get(variables,\n",
    "          { 'for': geo,\n",
    "            'in' : criteria},\n",
    "               year = year)\n",
    "df = pd.DataFrame(r).rename(columns={v: l for v, l in zip(variables, labels)})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7869b7c-5f92-4c78-bf51-0a207843a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from census import Census\n",
    "from us import states\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "\n",
    "'''\n",
    "* The following code pull in Census Data using the py API. Using the us library just like with previous calls, and the census library. I pulled in all avaiable data for all the years in ACS5 for all available counties.\n",
    "* All of the below variables were used. \n",
    "* It is important to note that these variables were seletect based on interest and some randonmly.\n",
    "* There is inconsitencies between some variables existing in some years and not in others. So in the final output, you will potentially notice some missing years.\n",
    "* The API itself was somewhat glitchy or unreliable at times. In come instances It stopped on for inputting to many variables. This needs to be explored further.\n",
    "'''\n",
    "\n",
    "# Configure logging to write errors to a file\n",
    "logging.basicConfig(\n",
    "    filename=\"errors.log\",\n",
    "    level=logging.ERROR,\n",
    "    format=\"%(asctime)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Load in your API key; replace API_KEY with your actual token\n",
    "key = \"Enter Key\"  # Replace with your Census API key\n",
    "c = Census(key)\n",
    "\n",
    "# Choose relevant census dataset\n",
    "dataset = c.acs5\n",
    "\n",
    "# Assign variable codes\n",
    "'''variables = (\n",
    "    \"B05001_001E\", \"B05001_002E\", \"B05001_003E\", \"B05002_001E\", \"B05002_002E\",\n",
    "    \"B05002_003E\", \"B05002_004E\", \"B05002_005E\", \"B05002_006E\", \"B05003_001E\",\n",
    "    \"B05003_002E\", \"B05003_003E\", \"B05003_004E\", \"B05005_001E\", \"B05005_002E\",\n",
    "    \"B05005_003E\", \"B05006_001E\", \"B05006_002E\", \"B05007_001E\", \"B05007_002E\",\n",
    "    \"B05007_003E\", \"B05010_001E\", \"B06007_001E\", \"B06007_004E\", \"B06007_005E\",\n",
    "    \"B06007_006E\", \"B06008_001E\", \"B06008_002E\", \"B06009_001E\", \"B06009_005E\",\n",
    "    \"B16005_001E\", \"B16010_001E\", \"B17021_001E\", \"B17021_002E\", \"B17021_003E\",\n",
    "    \"B22001_002E\", \"B22001_003E\", \"B01001_001E\", \"B01002_001E\", \"B01002_002E\",\n",
    "    \"B01002_003E\", \"B03002_001E\", \"B03002_003E\", \"B03002_004E\", \"B03002_006E\",\n",
    "    \"B03002_012E\", \"B15003_022E\", \"B15003_023E\", \"B15003_001E\", \"B17020_001E\",\n",
    "    \"B15003_024E\", \"B15003_025E\", \"B17020_002E\", \"B17020_003E\", \"B15003_017E\",\n",
    "    \"B19013_001E\", \"B19001_001E\", \"B19001_002E\", \"B19001_017E\", \"B19301_001E\",\n",
    "    \"B20005_001E\", \"B20005_002E\", \"B20005_003E\", \"B20005_004E\", \"B20005_005E\",\n",
    "    \"B20005_006E\", \"B25001_001E\", \"B02001_001E\", \"B02001_002E\", \"B02001_003E\",\n",
    "    \"B02001_004E\", \"B08006_001E\", \"B08006_002E\", \"B08006_003E\", \"B08006_008E\",\n",
    "    \"B11001_001E\", \"B11001_002E\", \"B11001_003E\", \"B13002_001E\", \"B13002_002E\",\n",
    "    \"B23001_001E\", \"B23001_002E\", \"B23001_007E\", \"B23001_008E\", \"B23001_009E\",\n",
    "    \"B25004_001E\", \"B25004_002E\", \"B25004_003E\", \"B25004_004E\", \"B25004_005E\",\n",
    "    \"B25004_006E\", \"B25004_007E\", \"B23025_001E\", \"B23025_002E\", \"B23025_003E\",\n",
    "    \"B23025_004E\", \"B23025_005E\", \"B25035_001E\", \"B25077_001E\", \"B25064_001E\",\n",
    "    \"B25105_001E\", \"B08014_001E\", \"B08014_002E\", \"B08014_003E\", \"B08014_004E\",\n",
    "    \"B08014_005E\", \"B08014_006E\", \"B08014_007E\", \"B08014_008E\", \"B08014_009E\",\n",
    "    \"B08014_010E\", \"B08014_011E\", \"B25032_001E\", \"B25032_002E\", \"B25032_003E\",\n",
    "    \"B17017_001E\", \"B14002_001E\", \"B14002_002E\", \"B14002_003E\", \"B14002_004E\",\n",
    "    \"B14002_005E\", \"B14002_006E\", \"B01001_002E\", \"B01001_026E\", \"B09001_001E\",\n",
    "    \"B09002_001E\", \"B16001_001E\", \"B16001_002E\", \"B16001_003E\", \"B16001_004E\",\n",
    "    \"B17001_002E\", \"B17001_031E\", \"B19313_001E\", \"B23006_001E\", \"B23006_002E\",\n",
    "    \"B23006_003E\", \"B23006_004E\", \"B23006_005E\", \"B25002_001E\", \"B25002_002E\",\n",
    "    \"B25063_001E\", \"B25071_001E\", \"B25087_001E\", \"B25091_001E\", \"B27001_001E\",\n",
    "    \"B27001_002E\", \"B27001_003E\", \"B08121_001E\", \"B08121_002E\", \"B08121_003E\",\n",
    "    \"B08121_004E\", \"B05006_003E\", \"B05006_005E\", \"B05006_008E\", \"B05007_004E\",\n",
    "    \"B05007_005E\", \"B05001_005E\", \"B05001_006E\", \"B17025_002E\", \"B17025_004E\",\n",
    "    \"B23006_007E\", \"B15012_002E\", \"B15012_003E\", \"B25075_002E\", \"B27020_003E\",\n",
    "    \"B05001_001M\",\"B05001_002M\",\"B05001_003M\",\"B05002_001M\",\"B05002_002M\",\n",
    "    \"B05002_003M\",\"B05002_004M\",\"B05002_005M\",\"B05002_006M\",\"B05003_001M\",\n",
    "    \"B05003_002M\",\"B05003_003M\",\"B05003_004M\",\"B05005_001M\",\"B05005_002M\",\n",
    "    \"B05005_003M\",\"B05006_001M\",\"B05006_002M\",\"B05007_001M\",\"B05007_002M\",\n",
    "    \"B05007_003M\",\"B05010_001M\",\"B06007_001M\",\"B06007_004M\",\"B06007_005M\",\n",
    "    \"B06007_006M\",\"B06008_001M\",\"B06008_002M\",\"B06009_001M\",\"B06009_005M\",\n",
    "    \"B16005_001M\",\"B16010_001M\",\"B17021_001M\",\"B17021_002M\",\"B17021_003M\",\n",
    "    \"B22001_002M\",\"B22001_003M\",\"B01001_001M\",\"B01002_001M\",\"B01002_002M\",\n",
    "    \"B01002_003M\",\"B03002_001M\",\"B03002_003M\",\"B03002_004M\",\"B03002_006M\",\n",
    "    \"B03002_012M\",\"B15003_022M\",\"B15003_023M\",\"B15003_001M\",\"B17020_001M\",\n",
    "    \"B15003_024M\",\"B15003_025M\",\"B17020_002M\",\"B17020_003M\",\"B15003_017M\",\n",
    "    \"B19013_001M\",\"B19001_001M\",\"B19001_002M\",\"B19001_017M\",\"B19301_001M\",\n",
    "    \"B20005_001M\",\"B20005_002M\",\"B20005_003M\",\"B20005_004M\",\"B20005_005M\",\n",
    "    \"B20005_006M\",\"B25001_001M\",\"B02001_001M\",\"B02001_002M\",\"B02001_003M\",\n",
    "    \"B02001_004M\",\"B08006_001M\",\"B08006_002M\",\"B08006_003M\",\"B08006_008M\",\n",
    "    \"B11001_001M\",\"B11001_002M\",\"B11001_003M\",\"B13002_001M\",\"B13002_002M\",\n",
    "    \"B23001_001M\",\"B23001_002M\",\"B23001_007M\",\"B23001_008M\",\"B23001_009M\",\n",
    "    \"B25004_001M\",\"B25004_002M\",\"B25004_003M\",\"B25004_004M\",\"B25004_005M\",\n",
    "    \"B25004_006M\",\"B25004_007M\",\"B23025_001M\",\"B23025_002M\",\"B23025_003M\",\n",
    "    \"B23025_004M\",\"B23025_005M\",\"B25035_001M\",\"B25077_001M\",\"B25064_001M\",\n",
    "    \"B25105_001M\",\"B08014_001M\",\"B08014_002M\",\"B08014_003M\",\"B08014_004M\",\n",
    "    \"B08014_005M\",\"B08014_006M\",\"B08014_007M\",\"B08014_008M\",\"B08014_009M\",\n",
    "    \"B08014_010M\",\"B08014_011M\",\"B25032_001M\",\"B25032_002M\",\"B25032_003M\",\n",
    "    \"B17017_001M\",\"B14002_001M\",\"B14002_002M\",\"B14002_003M\",\"B14002_004M\",\n",
    "    \"B14002_005M\",\"B14002_006M\",\"B01001_002M\",\"B01001_026M\",\"B09001_001M\",\n",
    "    \"B09002_001M\",\"B16001_001M\",\"B16001_002M\",\"B16001_003M\",\"B16001_004M\",\n",
    "    \"B17001_002M\",\"B17001_031M\",\"B19313_001M\",\"B23006_001M\",\"B23006_002M\",\n",
    "    \"B23006_003M\",\"B23006_004M\",\"B23006_005M\",\"B25002_001M\",\"B25002_002M\",\n",
    "    \"B25063_001M\",\"B25071_001M\",\"B25087_001M\",\"B25091_001M\",\"B27001_001M\",\n",
    "    \"B27001_002M\",\"B27001_003M\",\"B08121_001M\",\"B08121_002M\",\"B08121_003M\",\n",
    "    \"B08121_004M\",\"B05006_003M\",\"B05006_005M\",\"B05006_008M\",\"B05007_004M\",\n",
    "    \"B05007_005M\",\"B05001_005M\",\"B05001_006M\",\"B17025_002M\",\"B17025_004M\",\n",
    "    \"B23006_007M\",\"B15012_002M\",\"B15012_003M\",\"B25075_002M\",\"B27020_003M\"\n",
    ")'''\n",
    "# New Variables, some are the duplicates. So beware.\n",
    "variables = [\"B05001_001E\", \"B05001_002E\", \"B05001_003E\", \"B05001_004E\", \"B05001_005E\", \"B05001_006E\",\n",
    "    \"B05002_001E\", \"B05002_002E\", \"B05002_003E\", \"B05002_004E\", \"B05002_005E\", \"B05002_006E\",\n",
    "    \"B05002_007E\", \"B05002_008E\", \"B05002_009E\", \"B05002_010E\", \"B05002_011E\", \"B05002_012E\",\n",
    "    \"B05002_013E\", \"B05002_014E\", \"B05002_015E\", \"B05003_001E\", \"B05003_002E\", \"B05003_003E\",\n",
    "    \"B05003_004E\", \"B05003_005E\", \"B05003_006E\", \"B05003_007E\", \"B05003_008E\", \"B05003_009E\",\n",
    "    \"B05003_010E\", \"B05003_011E\", \"B05003_012E\", \"B05003_013E\", \"B05003_014E\", \"B05003_015E\",\n",
    "    \"B05003_016E\", \"B05003_017E\", \"B05003_018E\", \"B05003_019E\", \"B05003_020E\", \"B05003_021E\",\n",
    "    \"B05003_022E\", \"B05003_023E\", \"B05003A_001E\", \"B05003A_023E\", \"B05003B_001E\", \"B05003B_023E\",\n",
    "    \"B05003C_001E\", \"B05003C_023E\", \"B05003D_001E\",\n",
    "    \"B05003D_023E\", \"B05003E_001E\", \"B05003E_023E\", \"B05003F_001E\", \"B05003F_023E\",\n",
    "    \"B05003H_001E\", \"B05003H_023E\", \"B05003I_001E\", \"B05003I_023E\"\n",
    "]\n",
    "'''\n",
    "* The API call for some reason was breaking when using more than 150+ variable codes. It was very unstable, so dcreased the number to around 150. The above variable codes worked for me.\n",
    "* Excluded after testing some manually: B11012_001E, B11012_002E, B11012_003E, B11012_004E, B11012_005E, B24010_002E, B16002_002E, B16002_003E, B16002_004E\n",
    "* E: Estimate\n",
    "* M: Margin of Error\n",
    "'''\n",
    "\n",
    "# Initialize an empty list to collect results\n",
    "all_data = []\n",
    "\n",
    "# Available ACS 5-Year dataset years\n",
    "years = list(range(2010, 2023))  # Adjust year range as needed\n",
    "#years = [2015, 2016]\n",
    "\n",
    "# Function to process data for a single state in a year\n",
    "def fetch_state_data(state, year):\n",
    "    try:\n",
    "        state_fips = state.fips\n",
    "        state_name = state.name\n",
    "\n",
    "        # Fetch county list for the current state\n",
    "        counties = dataset.get(('NAME',), {'for': 'county:*', 'in': f'state:{state_fips}'}, year=year)\n",
    "        state_data = []\n",
    "\n",
    "        # Placeholder with all variables initialized to NA\n",
    "        placeholder = {var: \"NA\" for var in variables}\n",
    "        placeholder.update({\n",
    "            \"year\": year,\n",
    "            \"state_fips\": state_fips,\n",
    "            \"state_name\": state_name,\n",
    "            \"county_fips\": None,\n",
    "            \"county_name\": None\n",
    "        })\n",
    "\n",
    "        # Loop through counties in the state\n",
    "        for county in counties:\n",
    "            county_code = county['county']\n",
    "            county_name = county['NAME']\n",
    "            try:\n",
    "                r = dataset.get(\n",
    "                    variables,\n",
    "                    {'for': 'county subdivision:*', 'in': f'state:{state_fips} county:{county_code}'},\n",
    "                    year=year\n",
    "                )\n",
    "                for row in r:\n",
    "                    row.update({\n",
    "                        \"year\": year,\n",
    "                        \"state_fips\": state_fips,\n",
    "                        \"state_name\": state_name,\n",
    "                        \"county_fips\": county_code,\n",
    "                        \"county_name\": county_name\n",
    "                    })\n",
    "                    # Fill missing variables with NA\n",
    "                    complete_row = {**placeholder, **row}\n",
    "                    state_data.append(complete_row)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error fetching data for county {county_name} ({county_code}) in state {state_name} for year {year}: {e}\")\n",
    "        return state_data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching counties for state {state.name} in year {year}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Parallel processing for years\n",
    "for year in tqdm(years, desc=\"Processing Years\"):\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=15) as executor:\n",
    "            # Submit state processing tasks in parallel\n",
    "            futures = [executor.submit(fetch_state_data, state, year) for state in states.STATES]\n",
    "\n",
    "            # Collect results as tasks complete\n",
    "            for future in as_completed(futures):\n",
    "                all_data.extend(future.result())\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing year {year}: {e}\")\n",
    "\n",
    "# Convert collected data to a DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Reorder columns to place state and county information first\n",
    "column_order = ['year', 'state_fips', 'state_name', 'county_fips', 'county_name'] + [col for col in df.columns if col not in ['year', 'state_fips', 'state_name', 'county_fips', 'county_name']]\n",
    "df = df[column_order]\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_file = \"acs5_immigration_foreign_allyears.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "#parquet_path = \"acs5_immigration_foreign_allyears.parquet\"\n",
    "#df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "# Confirm completion\n",
    "print(f\"Data collection complete. Results saved to {output_file}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312c09f-f04f-412c-9062-0e16d645a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#######################################################################\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd7af38-76c7-4a0c-b37a-d645c7b58809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: I used this script for testing variable codes and the script. Code is the same as previous(above), except for the halt execution to stop when code runs into nonexistent variable codes for years.\n",
    "import pandas as pd\n",
    "from census import Census\n",
    "from us import states\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configure logging to write errors to a file\n",
    "logging.basicConfig(\n",
    "    filename=\"errors.log\",\n",
    "    level=logging.ERROR,\n",
    "    format=\"%(asctime)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Load in your API key; replace API_KEY with your actual token\n",
    "key = \"Enter Key\"  # Replace with your Census API key\n",
    "c = Census(key)\n",
    "\n",
    "# Choose relevant census dataset\n",
    "dataset = c.acs5\n",
    "\n",
    "# Assign variable codes\n",
    "'''variables = (\"B27001_002E\", \"B27001_003E\", \"B08121_001E\", \"B08121_002E\", \"B08121_003E\",\n",
    "             \"B08121_004E\", \"B05006_003E\", \"B05006_005E\", \"B05006_008E\", \"B05007_004E\",\n",
    "             \"B05007_005E\", \"B05001_005E\", \"B05001_006E\", \"B17025_002E\", \"B17025_004E\",\n",
    "             \"B23006_007E\", \"B15012_002E\", \"B15012_003E\", \"B25075_002E\", \"B27020_003E\",\n",
    "             \"B07003_001E\", \"B07003_003E\"\n",
    "            )'''\n",
    "variables = [\n",
    "    \"B05001_001E\", \"B05001_002E\", \"B05001_003E\", \"B05001_004E\", \"B05001_005E\", \"B05001_006E\",\n",
    "    \"B05002_001E\", \"B05002_002E\", \"B05002_003E\", \"B05002_004E\", \"B05002_005E\", \"B05002_006E\",\n",
    "    \"B05002_007E\", \"B05002_008E\", \"B05002_009E\", \"B05002_010E\", \"B05002_011E\", \"B05002_012E\",\n",
    "    \"B05002_013E\", \"B05002_014E\", \"B05002_015E\", \"B05003_001E\", \"B05003_002E\", \"B05003_003E\",\n",
    "    \"B05003_004E\", \"B05003_005E\", \"B05003_006E\", \"B05003_007E\", \"B05003_008E\", \"B05003_009E\",\n",
    "    \"B05003_010E\", \"B05003_011E\", \"B05003_012E\", \"B05003_013E\", \"B05003_014E\", \"B05003_015E\",\n",
    "    \"B05003_016E\", \"B05003_017E\", \"B05003_018E\", \"B05003_019E\", \"B05003_020E\", \"B05003_021E\",\n",
    "    \"B05003_022E\", \"B05003_023E\", \"B05003A_001E\", \"B05003A_023E\", \"B05003B_001E\", \"B05003B_023E\",\n",
    "    \"B05003C_001E\", \"B05003C_023E\", \"B05003D_001E\",\n",
    "    \"B05003D_023E\", \"B05003E_001E\", \"B05003E_023E\", \"B05003F_001E\", \"B05003F_023E\",\n",
    "    \"B05003H_001E\", \"B05003H_023E\", \"B05003I_001E\", \"B05003I_023E\"\n",
    "]\n",
    "#) #The AAPI call for some reason was breaking when using more than 150+ variable codes. It was very unstable, so dcreased the number to around 150. The above variable codes worked for me.\n",
    "# Excluded after testing some manually: B11012_001E, B11012_002E, B11012_003E, B11012_004E, B11012_005E, B24010_002E, B16002_002E, B16002_003E, B16002_004E\n",
    "\n",
    "# Available ACS 5-Year dataset years\n",
    "years = list(range(2010, 2023))  # Adjust year range as needed\n",
    "#years = [2015, 2022]  # Adjust as needed\n",
    "\n",
    "# Initialize an empty list to collect results\n",
    "all_data = []\n",
    "\n",
    "# Function to process data for a single state in a year\n",
    "def fetch_state_data(state, year):\n",
    "    try:\n",
    "        state_fips = state.fips\n",
    "        state_name = state.name\n",
    "\n",
    "        # Fetch county list for the current state\n",
    "        counties = dataset.get(('NAME',), {'for': 'county:*', 'in': f'state:{state_fips}'}, year=year)\n",
    "        state_data = []\n",
    "\n",
    "        # Placeholder with all variables initialized to NA\n",
    "        placeholder = {var: \"NA\" for var in variables}\n",
    "        placeholder.update({\n",
    "            \"year\": year,\n",
    "            \"state_fips\": state_fips,\n",
    "            \"state_name\": state_name,\n",
    "            \"county_fips\": None,\n",
    "            \"county_name\": None\n",
    "        })\n",
    "\n",
    "        # Loop through counties in the state\n",
    "        for county in counties:\n",
    "            county_code = county['county']\n",
    "            county_name = county['NAME']\n",
    "            try:\n",
    "                r = dataset.get(\n",
    "                    variables,\n",
    "                    {'for': 'county subdivision:*', 'in': f'state:{state_fips} county:{county_code}'},\n",
    "                    year=year\n",
    "                )\n",
    "                if not r:  # If API response is empty\n",
    "                    logging.warning(f\"No data returned for county {county_name} ({county_code}) in state {state_name} for year {year}.\")\n",
    "                    placeholder.update({\n",
    "                        \"county_fips\": county_code,\n",
    "                        \"county_name\": county_name\n",
    "                    })\n",
    "                    state_data.append(placeholder.copy())\n",
    "                else:\n",
    "                    for row in r:\n",
    "                        row.update({\n",
    "                            \"year\": year,\n",
    "                            \"state_fips\": state_fips,\n",
    "                            \"state_name\": state_name,\n",
    "                            \"county_fips\": county_code,\n",
    "                            \"county_name\": county_name\n",
    "                        })\n",
    "                        # Fill missing variables with NA\n",
    "                        complete_row = {**placeholder, **row}\n",
    "                        state_data.append(complete_row)\n",
    "            except Exception as e:\n",
    "                error_message = f\"Nonexistent variable encountered for county {county_name} ({county_code}) in state {state_name} for year {year}: {e}\"\n",
    "                logging.error(error_message)\n",
    "                sys.exit(error_message)\n",
    "        return state_data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching counties for state {state.name} in year {year}: {e}\")\n",
    "        sys.exit(f\"Error fetching counties for state {state.name} in year {year}: {e}\")\n",
    "\n",
    "# Parallel processing for years\n",
    "for year in tqdm(years, desc=\"Processing Years\"):\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            # Submit state processing tasks in parallel\n",
    "            futures = [executor.submit(fetch_state_data, state, year) for state in states.STATES]\n",
    "\n",
    "            # Collect results as tasks complete\n",
    "            for future in as_completed(futures):\n",
    "                all_data.extend(future.result())\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing year {year}: {e}\")\n",
    "        sys.exit(f\"Error processing year {year}: {e}\")\n",
    "\n",
    "# Convert collected data to a DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Reorder columns to place state and county information first\n",
    "default_columns = ['year', 'state_fips', 'state_name', 'county_fips', 'county_name'] + list(variables)\n",
    "for col in default_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = \"NA\"\n",
    "\n",
    "column_order = ['year', 'state_fips', 'state_name', 'county_fips', 'county_name'] + [col for col in df.columns if col not in ['year', 'state_fips', 'state_name', 'county_fips', 'county_name']]\n",
    "df = df[column_order]\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_file = \"acs5_immigration_foreign_allyears.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "#parquet_path = \"acs5_immigration_foreign_allyears.parquet\"\n",
    "#df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "# Confirm completion\n",
    "print(f\"Data collection complete. Results saved to {output_file}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c6a6d-ce2c-4dc3-afca-93fe3e004a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two Census dataframes. After identfying some inconsistencies with the first pulled variable codes. \n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "file1_path = 'acs5_immigration_foreign_allyears_new.csv'  # Replace with the actual path to your first CSV file\n",
    "file2_path = 'acs5_immigration_foreign_allyears.csv'  # Replace with the actual path to your second CSV file\n",
    "\n",
    "# Read the CSV files\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Merge the DataFrames on 'year' and 'county_name'\n",
    "merged_df = pd.merge(df1, df2, on=['year','state_fips','state_name','county_fips','county_name', 'GEO_ID', 'state', 'county', 'county subdivision'], how='inner')\n",
    "\n",
    "# Output the merged DataFrame to a new CSV file\n",
    "output_path = 'acs5_immigration_foreign_allyears_final.csv'  # Replace with your desired output path\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Merged file saved to: {output_path}\")\n",
    "print(merged_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
